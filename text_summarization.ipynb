{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db8ff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: umap-learn in /home/nate/miniconda3/lib/python3.9/site-packages (0.5.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /home/nate/miniconda3/lib/python3.9/site-packages (from umap-learn) (0.5.6)\n",
      "Requirement already satisfied: tqdm in /home/nate/miniconda3/lib/python3.9/site-packages (from umap-learn) (4.63.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/nate/miniconda3/lib/python3.9/site-packages (from umap-learn) (1.21.4)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/nate/miniconda3/lib/python3.9/site-packages (from umap-learn) (1.7.2)\n",
      "Requirement already satisfied: numba>=0.49 in /home/nate/miniconda3/lib/python3.9/site-packages (from umap-learn) (0.55.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /home/nate/miniconda3/lib/python3.9/site-packages (from umap-learn) (1.0.2)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/nate/miniconda3/lib/python3.9/site-packages (from numba>=0.49->umap-learn) (0.38.0)\n",
      "Requirement already satisfied: setuptools in /home/nate/miniconda3/lib/python3.9/site-packages (from numba>=0.49->umap-learn) (52.0.0.post20210125)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/nate/miniconda3/lib/python3.9/site-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/nate/miniconda3/lib/python3.9/site-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de364c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "from rouge import Rouge\n",
    "import umap\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf8d82a",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1413662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nate/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf6c0f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nate/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e31e4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/nate/.cache/huggingface/datasets/ccdv___cnn_dailymail/3.0.0/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436c7f745875445db745941ca45809d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ccdv/cnn_dailymail\", '3.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc5bae6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "444288f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-22 12:17:10--  http://mlg.ucd.ie/files/datasets/bbc.zip\n",
      "Resolving mlg.ucd.ie (mlg.ucd.ie)... 137.43.93.132\n",
      "Connecting to mlg.ucd.ie (mlg.ucd.ie)|137.43.93.132|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 884338 (864K) [application/zip]\n",
      "Saving to: ‘bbc.zip’\n",
      "\n",
      "bbc.zip             100%[===================>] 863.61K  1.29MB/s    in 0.7s    \n",
      "\n",
      "2022-04-22 12:17:12 (1.29 MB/s) - ‘bbc.zip’ saved [884338/884338]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://mlg.ucd.ie/files/datasets/bbc.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79995cf0",
   "metadata": {},
   "source": [
    "# Pretrained word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2857ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(filename, skip_first_line=False, emb_dim=300):\n",
    "    \"\"\" Returns an awesome dictionary that maps tokens to vectors\n",
    "    NOTE: skip_first_line = False if glove else True\n",
    "\n",
    "    Params:\n",
    "        filename (str): name of vector file (likely with .vec suffix)\n",
    "        skip_first_line (bool): is there a useless line at the top of the .vec file that we need to skip?\n",
    "        emb_dim (int): embedding dimension of embeddings\n",
    "    Returns:\n",
    "        embeddings_dict (dict): dictionary mapping words to embeddings\n",
    "            dict = { \"word\" (str) : vec (numpy.ndarray), ... }\n",
    "    \"\"\"\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    embeddings_dict = {}\n",
    "    if skip_first_line:\n",
    "        # Skip the very first line because it's just info about the doc\n",
    "        lines = lines[1:]\n",
    "    for i, l in enumerate(lines):\n",
    "        tokens = l.encode('utf-8').split()\n",
    "        # embeddings_dict maps a string to a vector\n",
    "        try:\n",
    "            embeddings_dict[tokens[0]] = np.array([float(token) for token in tokens[-emb_dim:]])\n",
    "        except:\n",
    "            pdb.set_trace()\n",
    "            while not tokens[1][3].isdigit():\n",
    "                tokens = [tokens[0]+tokens[1]] + tokens[2:]\n",
    "            # try again\n",
    "            embeddings_dict[tokens[0]] = np.array([float(token) for token in tokens[1:]])\n",
    "            assert len(embeddings_dict[tokens[0]]) == emb_dim\n",
    "        \n",
    "        try:\n",
    "            float_tok = float(tokens[0])\n",
    "            if '.' in tokens[0] and not (tokens[0].index('.') == len(tokens[0]) - 1):\n",
    "                pdb.set_trace()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if i%25000 ==0:\n",
    "            print(i,flush=True)\n",
    "            \n",
    "    return embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a31726b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embedding_path = \"/home/nate/CODE/embeddings/all_embeds/word2vecC3.IN\"\n",
    "context_embedding_path = \"/home/nate/CODE/embeddings/all_embeds/word2vecC3.OUT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdab43c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25000\n",
      "50000\n",
      "75000\n",
      "100000\n",
      "125000\n",
      "150000\n",
      "175000\n",
      "200000\n",
      "225000\n",
      "250000\n",
      "275000\n",
      "300000\n",
      "325000\n",
      "350000\n",
      "375000\n",
      "400000\n",
      "425000\n"
     ]
    }
   ],
   "source": [
    "target_embeddings = load_embeddings(target_embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd5ade5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25000\n",
      "50000\n",
      "75000\n",
      "100000\n",
      "125000\n",
      "150000\n",
      "175000\n",
      "200000\n",
      "225000\n",
      "250000\n",
      "275000\n",
      "300000\n",
      "325000\n",
      "350000\n",
      "375000\n",
      "400000\n",
      "425000\n"
     ]
    }
   ],
   "source": [
    "context_embeddings = load_embeddings(context_embedding_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c89253",
   "metadata": {},
   "source": [
    "# TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f8ff239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(document):\n",
    "    sentences =[]        \n",
    "    sentences = sent_tokenize(document)    \n",
    "    for sentence in sentences:        \n",
    "        sentence.replace(\"[^a-zA-Z0-9]\",\" \")     \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d5debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_cosine_similarity(sent1, sent2, stopwords=None, embedding_dict=None):    \n",
    "    if stopwords is None:        \n",
    "        stopwords = []        \n",
    "    sent1 = [w.lower() for w in sent1]    \n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "\n",
    "    all_words = list(set(sent1 + sent2))   \n",
    "\n",
    "    vector1 = [0] * len(all_words)    \n",
    "    vector2 = [0] * len(all_words)        \n",
    "    #build the vector for the first sentence    \n",
    "    for w in sent1:        \n",
    "        if not w in stopwords:\n",
    "            vector1[all_words.index(w)]+=1                                                             \n",
    "    #build the vector for the second sentence    \n",
    "    for w in sent2:        \n",
    "        if not w in stopwords:            \n",
    "            vector2[all_words.index(w)]+=1 \n",
    "\n",
    "    return 1-cosine_distance(vector1,vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d454ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_similarity(sent1, sent2, stopwords=None, embedding_dict=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    "    n1 = len(sent1)\n",
    "    n2 = len(sent2)\n",
    "    sent1 = [w.lower() for w in sent1.split()]\n",
    "    sent2 = [w.lower() for w in sent2.split()]\n",
    "    words = sent1 + sent2\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if not word in stopwords:\n",
    "            if word in sent1 and word in sent2:\n",
    "                count += 1\n",
    "    return count / (np.log(n1) + np.log(n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aa0417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_similarity(sent1, sent2, stopwords, embedding_dict):\n",
    "    sent1 = [w.lower() for w in sent1.split()]\n",
    "    sent2 = [w.lower() for w in sent2.split()]\n",
    "    \n",
    "    # construct bag-of-words representation of sentences\n",
    "    v1 = np.zeros(300)\n",
    "    for i in range(len(sent1)):\n",
    "        try:\n",
    "            v1 += embedding_dict[sent1[i].encode()]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    v2 = np.zeros(300)\n",
    "    for i in range(len(sent2)):\n",
    "        try:\n",
    "            v2 += embedding_dict[sent2[i].encode()]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    return 1 - scipy.spatial.distance.cosine(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd654e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(sentences, similarity_measure, stopwords=None, embedding_dict=None):\n",
    "    n = len(sentences)\n",
    "    sim_mat = np.zeros((n, n))\n",
    "    # O(n^2)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if embedding_dict is not None:\n",
    "                sim_mat[i][j] = similarity_measure(sentences[i], sentences[j], stopwords, embedding_dict)\n",
    "            else:\n",
    "                sim_mat[i][j] = similarity_measure(sentences[i], sentences[j], stopwords)\n",
    "    return sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2c9aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(document, n, similarity_measure, stopwords=None, embedding_dict=None):\n",
    "    # Tokenize sentences\n",
    "    sentences = tokenize_sentences(document)\n",
    "    \n",
    "    # Build similarity matrix\n",
    "    sim_mat = similarity_matrix(sentences, similarity_measure, stopwords, embedding_dict)\n",
    "    \n",
    "    # Rank sentences using page rank\n",
    "    sim_graph = nx.from_numpy_array(sim_mat)\n",
    "    scores = nx.pagerank(sim_graph, max_iter=10000)\n",
    "    \n",
    "    # Rank sentences\n",
    "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)),reverse=True)\n",
    "    \n",
    "    # Generate summary\n",
    "    summary = []\n",
    "    for i in range(n):\n",
    "        summary.append(ranked_sentences[i][1])\n",
    "        \n",
    "    return \" \".join(summary), len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191bcdef",
   "metadata": {},
   "source": [
    "# BBC News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bac4cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(base_article_path, base_summary_path, files):\n",
    "  articles = []\n",
    "  summaries = []\n",
    "  for file in files:\n",
    "    with open(base_article_path+\"/\"+file, \"r\", encoding=\"unicode_escape\") as f:\n",
    "      articles.append(f.read())\n",
    "    with open(base_summary_path+\"/\"+file, \"r\", encoding=\"unicode_escape\") as f:\n",
    "      summaries.append(f.read())\n",
    "  \n",
    "  return articles, summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c31db414",
   "metadata": {},
   "outputs": [],
   "source": [
    "business = os.listdir(\"BBC News Summary/News Articles/business\")\n",
    "entertainment = os.listdir(\"BBC News Summary/News Articles/entertainment\")\n",
    "politics = os.listdir(\"BBC News Summary/News Articles/politics\")\n",
    "sports = os.listdir(\"BBC News Summary/News Articles/sport\")\n",
    "tech = os.listdir(\"BBC News Summary/News Articles/tech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28a857e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_articles, business_summaries = get_articles(\"BBC News Summary/News Articles/business\", \\\n",
    "                                                     \"BBC News Summary/Summaries/business\", \\\n",
    "                                                     business)\n",
    "entertainment_articles, entertainment_summaries = get_articles(\"BBC News Summary/News Articles/entertainment\", \\\n",
    "                                                               \"BBC News Summary/Summaries/entertainment\", \\\n",
    "                                                               entertainment)\n",
    "politics_articles, politics_summaries = get_articles(\"BBC News Summary/News Articles/politics\", \\\n",
    "                                                     \"BBC News Summary/Summaries/politics\", \\\n",
    "                                                     politics)\n",
    "sports_articles, sports_summaries = get_articles(\"BBC News Summary/News Articles/sport\", \\\n",
    "                                                 \"BBC News Summary/Summaries/sport\", \\\n",
    "                                                 sports)\n",
    "tech_articles, tech_summaries = get_articles(\"BBC News Summary/News Articles/tech\", \\\n",
    "                                             \"BBC News Summary/Summaries/tech\", \\\n",
    "                                             tech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5171a8b3",
   "metadata": {},
   "source": [
    "# BBC News TextRank Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c7e2052",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english') \n",
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eca9322c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "target rouge-1 0.5425430148723613\n",
      "target rouge-2 0.4287122137845125\n",
      "target rouge-L 0.532401312954358\n",
      "\n",
      "context rouge-1 0.5674636996688391\n",
      "context rouge-2 0.45827095489469094\n",
      "context rouge-L 0.5586380118116964\n"
     ]
    }
   ],
   "source": [
    "target_business = {\"1\": [], \"2\": [], \"L\": []}\n",
    "context_business = {\"1\": [], \"2\": [], \"L\": []}\n",
    "i = 0\n",
    "for article, highlight in zip(business_articles, business_summaries):\n",
    "    # target summary\n",
    "    summary, _ = summarize(article, 3, w2v_similarity, embedding_dict=target_embeddings)\n",
    "    scores = rouge.get_scores(summary, highlight)[0]\n",
    "    target_business[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    target_business[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    target_business[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    # context summary\n",
    "    summary, _ = summarize(article, 3, w2v_similarity, embedding_dict=context_embeddings)\n",
    "    scores = rouge.get_scores(summary, highlight)[0]\n",
    "    context_business[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    context_business[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    context_business[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print(\"target rouge-1\", np.mean(target_business[\"1\"]))\n",
    "print(\"target rouge-2\", np.mean(target_business[\"2\"]))\n",
    "print(\"target rouge-L\", np.mean(target_business[\"L\"]))\n",
    "print()\n",
    "print(\"context rouge-1\", np.mean(context_business[\"1\"]))\n",
    "print(\"context rouge-2\", np.mean(context_business[\"2\"]))\n",
    "print(\"context rouge-L\", np.mean(context_business[\"L\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b15593b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "target rouge-1 0.5416826387142711\n",
      "target rouge-2 0.43542617766859765\n",
      "target rouge-L 0.5325591263247877\n",
      "\n",
      "context rouge-1 0.5657993455510716\n",
      "context rouge-2 0.45833600701959804\n",
      "context rouge-L 0.5567330002328924\n"
     ]
    }
   ],
   "source": [
    "target_entertainment = {\"1\": [], \"2\": [], \"L\": []}\n",
    "context_entertainment = {\"1\": [], \"2\": [], \"L\": []}\n",
    "i = 0\n",
    "for article, highlight in zip(entertainment_articles, entertainment_summaries):\n",
    "    # target summary\n",
    "    summary, _ = summarize(article, 3, w2v_similarity, embedding_dict=target_embeddings)\n",
    "    scores = rouge.get_scores(summary, highlight)[0]\n",
    "    target_entertainment[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    target_entertainment[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    target_entertainment[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    # context summary\n",
    "    summary, _ = summarize(article, 3, w2v_similarity, embedding_dict=context_embeddings)\n",
    "    scores = rouge.get_scores(summary, highlight)[0]\n",
    "    context_entertainment[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    context_entertainment[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    context_entertainment[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print(\"target rouge-1\", np.mean(target_entertainment[\"1\"]))\n",
    "print(\"target rouge-2\", np.mean(target_entertainment[\"2\"]))\n",
    "print(\"target rouge-L\", np.mean(target_entertainment[\"L\"]))\n",
    "print()\n",
    "print(\"context rouge-1\", np.mean(context_entertainment[\"1\"]))\n",
    "print(\"context rouge-2\", np.mean(context_entertainment[\"2\"]))\n",
    "print(\"context rouge-L\", np.mean(context_entertainment[\"L\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31fb3348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "target rouge-1 0.5372009751430405\n",
      "target rouge-2 0.4276518268172094\n",
      "target rouge-L 0.5263915668989169\n",
      "\n",
      "context rouge-1 0.5281752005732037\n",
      "context rouge-2 0.41182480402834887\n",
      "context rouge-L 0.5176754380614679\n"
     ]
    }
   ],
   "source": [
    "target_politics = {\"1\": [], \"2\": [], \"L\": []}\n",
    "context_politics = {\"1\": [], \"2\": [], \"L\": []}\n",
    "i = 0\n",
    "for article, highlight in zip(politics_articles, politics_summaries):\n",
    "    # target summary\n",
    "    summary, _ = summarize(article, 3, w2v_similarity, embedding_dict=target_embeddings)\n",
    "    scores = rouge.get_scores(summary, highlight)[0]\n",
    "    target_politics[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    target_politics[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    target_politics[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    # context summary\n",
    "    summary, _ = summarize(article, 3, w2v_similarity, embedding_dict=context_embeddings)\n",
    "    scores = rouge.get_scores(summary, highlight)[0]\n",
    "    context_politics[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    context_politics[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    context_politics[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print(\"target rouge-1\", np.mean(target_politics[\"1\"]))\n",
    "print(\"target rouge-2\", np.mean(target_politics[\"2\"]))\n",
    "print(\"target rouge-L\", np.mean(target_politics[\"L\"]))\n",
    "print()\n",
    "print(\"context rouge-1\", np.mean(context_politics[\"1\"]))\n",
    "print(\"context rouge-2\", np.mean(context_politics[\"2\"]))\n",
    "print(\"context rouge-L\", np.mean(context_politics[\"L\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "433b1849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "target rouge-1 0.5204186873058985\n",
      "target rouge-2 0.41204452910686484\n",
      "target rouge-L 0.5104102826594811\n",
      "\n",
      "context rouge-1 0.5294455351833616\n",
      "context rouge-2 0.4177728102079702\n",
      "context rouge-L 0.5192517238535593\n"
     ]
    }
   ],
   "source": [
    "target_sports = {\"1\": [], \"2\": [], \"L\": []}\n",
    "context_sports = {\"1\": [], \"2\": [], \"L\": []}\n",
    "i = 0\n",
    "for article, highlight in zip(sports_articles, sports_summaries):\n",
    "    # target summary\n",
    "    try:\n",
    "        summary, _ = summarize(article, 3, w2v_similarity, embedding_dict=target_embeddings)\n",
    "    except:\n",
    "        continue\n",
    "    scores = rouge.get_scores(summary, highlight)[0]\n",
    "    target_sports[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    target_sports[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    target_sports[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    # context summary\n",
    "    summary, _ = summarize(article, 3, w2v_similarity, embedding_dict=context_embeddings)\n",
    "    scores = rouge.get_scores(summary, highlight)[0]\n",
    "    context_sports[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    context_sports[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    context_sports[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print(\"target rouge-1\", np.mean(target_sports[\"1\"]))\n",
    "print(\"target rouge-2\", np.mean(target_sports[\"2\"]))\n",
    "print(\"target rouge-L\", np.mean(target_sports[\"L\"]))\n",
    "print()\n",
    "print(\"context rouge-1\", np.mean(context_sports[\"1\"]))\n",
    "print(\"context rouge-2\", np.mean(context_sports[\"2\"]))\n",
    "print(\"context rouge-L\", np.mean(context_sports[\"L\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6174d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "target rouge-1 0.49210714212948176\n",
      "target rouge-2 0.3685661796295605\n",
      "target rouge-L 0.4808436792128448\n",
      "\n",
      "context rouge-1 0.49855760736933735\n",
      "context rouge-2 0.37113195428931295\n",
      "context rouge-L 0.4867380537888442\n"
     ]
    }
   ],
   "source": [
    "target_tech = {\"1\": [], \"2\": [], \"L\": []}\n",
    "context_tech = {\"1\": [], \"2\": [], \"L\": []}\n",
    "i = 0\n",
    "for article, highlight in zip(tech_articles, tech_summaries):\n",
    "    # target summary\n",
    "    try:\n",
    "        summary, _ = summarize(article, 3, w2v_similarity, embedding_dict=target_embeddings)\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        scores = rouge.get_scores(summary, highlight)[0]\n",
    "    except:\n",
    "        continue\n",
    "    target_tech[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    target_tech[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    target_tech[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    # context summary\n",
    "    summary, _ = summarize(article, 3, w2v_similarity, embedding_dict=context_embeddings)\n",
    "    scores = rouge.get_scores(summary, highlight)[0]\n",
    "    context_tech[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    context_tech[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    context_tech[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print(\"target rouge-1\", np.mean(target_tech[\"1\"]))\n",
    "print(\"target rouge-2\", np.mean(target_tech[\"2\"]))\n",
    "print(\"target rouge-L\", np.mean(target_tech[\"L\"]))\n",
    "print()\n",
    "print(\"context rouge-1\", np.mean(context_tech[\"1\"]))\n",
    "print(\"context rouge-2\", np.mean(context_tech[\"2\"]))\n",
    "print(\"context rouge-L\", np.mean(context_tech[\"L\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2765b758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.4080205847264073, pvalue=0.15919849618893975)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_all_r1 = target_tech[\"L\"] + target_entertainment[\"L\"] + target_politics[\"L\"] + \\\n",
    "                target_sports[\"L\"] + target_tech[\"L\"]\n",
    "context_all_r1 = context_tech[\"L\"] + context_entertainment[\"L\"] + context_politics[\"L\"] + \\\n",
    "                context_sports[\"L\"] + context_tech[\"L\"]\n",
    "from scipy.stats import ttest_ind\n",
    "ttest_ind(target_all_r1, context_all_r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c0e9d6",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "### Base Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4dfb2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = dataset[\"test\"][\"article\"][25]\n",
    "highlights = dataset[\"test\"][\"highlights\"][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98419f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b5f74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "508dd5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Summary:\n",
      "Nairobi, Kenya (CNN)University of Nairobi students were terrified Sunday morning when they heard explosions -- caused by a faulty electrical cable -- and believed it was a terror attack, the school said. Kenya Power authorities and its CEO are at the school and looking into the electrical issue. The confusion and panic came less than two weeks after Al-Shabaab slaughtered 147 people at a college in Garissa, Kenya.\n",
      "\n",
      "N-Gram Similarity Summary:\n",
      "Nairobi, Kenya (CNN)University of Nairobi students were terrified Sunday morning when they heard explosions -- caused by a faulty electrical cable -- and believed it was a terror attack, the school said. Students on the Kikuyu campus stampeded down the halls of the Kimberly dormitory, and some jumped from its fifth floor, the university said. Almost all of the 54 students being treated at PCEA Kikuyu Hospital have been released, the university said.\n",
      "\n",
      "Target Summary:\n",
      "Students stampeded; some jumped from a fifth story at a dorm; one student died, school officials say .\n",
      "The blasts were caused by faulty electrical cable, and Kenya Power is at the school .\n",
      "The panic came less than two weeks after terrorists attacked Kenya's Garissa University .\n"
     ]
    }
   ],
   "source": [
    "cos_similarity_summary = summarize(article, 3, bow_cosine_similarity, stop_words)\n",
    "print(\"Cosine Similarity Summary:\", cos_similarity_summary[0], sep=\"\\n\")\n",
    "print()\n",
    "ngram_similarity_summary = summarize(article, 3, ngram_similarity, stop_words)\n",
    "print(\"N-Gram Similarity Summary:\", ngram_similarity_summary[0], sep=\"\\n\")\n",
    "print()\n",
    "print(\"Target Summary:\", highlights, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "48f691c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Rouge Scores: \n",
      "{'r': 0.4878048780487805, 'p': 0.36363636363636365, 'f': 0.41666666177300354}\n",
      "N-Gram Similarity Rouge Scores: \n",
      "{'r': 0.3902439024390244, 'p': 0.2807017543859649, 'f': 0.3265306073781758}\n"
     ]
    }
   ],
   "source": [
    "cos_sim_scores = rouge.get_scores(cos_similarity_summary[0], highlights)[0]['rouge-1']\n",
    "print(\"Cosine Similarity Rouge Scores: \", cos_sim_scores, sep=\"\\n\")\n",
    "ngram_scores = rouge.get_scores(ngram_similarity_summary[0], highlights)[0]['rouge-1']\n",
    "print(\"N-Gram Similarity Rouge Scores: \", ngram_scores, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f9c9f",
   "metadata": {},
   "source": [
    "### Using Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1d1de7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Embedding Summary: \n",
      "Almost all of the 54 students being treated at PCEA Kikuyu Hospital have been released, the university said. Among them, at least 63 students have been discharged, and at least four are slated for surgery, the school said. The confusion and panic came less than two weeks after Al-Shabaab slaughtered 147 people at a college in Garissa, Kenya.\n",
      "\n",
      "Context Embedding Summary: \n",
      "Almost all of the 54 students being treated at PCEA Kikuyu Hospital have been released, the university said. Nairobi, Kenya (CNN)University of Nairobi students were terrified Sunday morning when they heard explosions -- caused by a faulty electrical cable -- and believed it was a terror attack, the school said. Students on the Kikuyu campus stampeded down the halls of the Kimberly dormitory, and some jumped from its fifth floor, the university said.\n",
      "\n",
      "Target Summary:\n",
      "Students stampeded; some jumped from a fifth story at a dorm; one student died, school officials say .\n",
      "The blasts were caused by faulty electrical cable, and Kenya Power is at the school .\n",
      "The panic came less than two weeks after terrorists attacked Kenya's Garissa University .\n",
      "\n",
      "Target Rouge Scores: \n",
      "{'r': 0.34146341463414637, 'p': 0.2978723404255319, 'f': 0.318181813205062}\n",
      "Context Rouge Scores: \n",
      "{'r': 0.3902439024390244, 'p': 0.2807017543859649, 'f': 0.3265306073781758}\n"
     ]
    }
   ],
   "source": [
    "target_embedding_summary = summarize(article, 3, w2v_similarity, stopwords, target_embeddings)\n",
    "print(\"Target Embedding Summary: \", target_embedding_summary[0], sep=\"\\n\")\n",
    "print()\n",
    "context_embedding_summary = summarize(article, 3, w2v_similarity, stopwords, context_embeddings)\n",
    "print(\"Context Embedding Summary: \", context_embedding_summary[0], sep=\"\\n\")\n",
    "print()\n",
    "print(\"Target Summary:\", highlights, sep=\"\\n\")\n",
    "print()\n",
    "target_scores = rouge.get_scores(target_embedding_summary[0], highlights)[0]['rouge-1']\n",
    "print(\"Target Rouge Scores: \", target_scores, sep=\"\\n\")\n",
    "context_scores = rouge.get_scores(context_embedding_summary[0], highlights)[0]['rouge-1']\n",
    "print(\"Context Rouge Scores: \", context_scores, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f26fc2",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4272287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "bow_scores = {\"1\": [], \"2\": [], \"L\": []}\n",
    "n_gram_scores = {\"1\": [], \"2\": [], \"L\": []}\n",
    "test = dataset[\"test\"]\n",
    "test_indices = np.arange(len(test))\n",
    "np.random.shuffle(test_indices)\n",
    "test_indices = test_indices[:500]\n",
    "for i, idx in enumerate(test_indices):\n",
    "    article = test[\"article\"][idx]\n",
    "    highlights = test[\"highlights\"][idx]\n",
    "    \n",
    "    target_summary = summarize(article, 3, bow_cosine_similarity, stopwords=stop_words)\n",
    "    scores = rouge.get_scores(target_summary[0], highlights)[0]\n",
    "    bow_scores[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    bow_scores[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    bow_scores[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    context_summary = summarize(article, 3, ngram_similarity, stopwords=stop_words)\n",
    "    scores = rouge.get_scores(context_summary[0], highlights)[0]\n",
    "    n_gram_scores[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    n_gram_scores[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    n_gram_scores[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb51ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bow mean rouge scores: \", np.mean(bow_scores[\"r\"]))\n",
    "print(\"n gram mean rouge scores: \", np.mean(n_gram_scores[\"r\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f8ea6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'r'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget embedding mean rouge scores: \u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mtarget_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext embedding mean rouge scores: \u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(context_scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'r'"
     ]
    }
   ],
   "source": [
    "target_scores = {\"1\": [], \"2\": [], \"L\": []}\n",
    "context_scores = {\"1\": [], \"2\": [], \"L\": []}\n",
    "for i, idx in enumerate(test_indices):\n",
    "    article = test[\"article\"][idx]\n",
    "    highlights = test[\"highlights\"][idx]\n",
    "    \n",
    "    target_summary = summarize(article, 3, w2v_similarity, stopwords, target_embeddings)\n",
    "    scores = rouge.get_scores(target_summary[0], highlights)[0]\n",
    "    target_scores[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    target_scores[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    target_scores[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    context_summary = summarize(article, 3, w2v_similarity, stopwords, context_embeddings)\n",
    "    scores = rouge.get_scores(context_summary[0], highlights)[0]\n",
    "    context_scores[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    context_scores[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    context_scores[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c8d7431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target embedding mean rouge-1 scores:  0.25334375015645244\n",
      "context embedding mean rouge-1 scores:  0.2641069037352692\n",
      "target embedding mean rouge-2 scores:  0.07373836767943234\n",
      "context embedding mean rouge-2 scores:  0.081666750998527\n",
      "target embedding mean rouge-L scores:  0.22810958723690078\n",
      "context embedding mean rouge-L scores:  0.23807968970506777\n"
     ]
    }
   ],
   "source": [
    "print(\"target embedding mean rouge-1 scores: \", np.mean(target_scores[\"1\"]))\n",
    "print(\"context embedding mean rouge-1 scores: \", np.mean(context_scores[\"1\"]))\n",
    "\n",
    "print(\"target embedding mean rouge-2 scores: \", np.mean(target_scores[\"2\"]))\n",
    "print(\"context embedding mean rouge-2 scores: \", np.mean(context_scores[\"2\"]))\n",
    "\n",
    "print(\"target embedding mean rouge-L scores: \", np.mean(target_scores[\"L\"]))\n",
    "print(\"context embedding mean rouge-L scores: \", np.mean(context_scores[\"L\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc3c39f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.3439988122790347, pvalue=0.019273609593215092)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "ttest_ind(target_scores[\"r\"], context_scores[\"r\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e4b010",
   "metadata": {},
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31b41c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 3.2 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /home/nate/miniconda3/lib/python3.9/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /home/nate/miniconda3/lib/python3.9/site-packages (from kaggle) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil in /home/nate/miniconda3/lib/python3.9/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /home/nate/miniconda3/lib/python3.9/site-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: tqdm in /home/nate/miniconda3/lib/python3.9/site-packages (from kaggle) (4.63.0)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-6.1.1-py2.py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: urllib3 in /home/nate/miniconda3/lib/python3.9/site-packages (from kaggle) (1.26.6)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<5,>=3.0.2 in /home/nate/miniconda3/lib/python3.9/site-packages (from requests->kaggle) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/nate/miniconda3/lib/python3.9/site-packages (from requests->kaggle) (2.10)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73053 sha256=5711b5305ee460b99f12bedffaccdd29662578d99849ce042d6cf407247d47a3\n",
      "  Stored in directory: /home/nate/.cache/pip/wheels/ac/b2/c3/fa4706d469b5879105991d1c8be9a3c2ef329ba9fe2ce5085e\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.12 python-slugify-6.1.1 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ffd06d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7942031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/nate/.kaggle/kaggle.json'\n",
      "Downloading bbc-news-summary.zip to /home/nate/CODE/TextSummarization\n",
      " 56%|█████████████████████▎                | 5.00M/8.91M [00:00<00:00, 48.6MB/s]\n",
      "100%|██████████████████████████████████████| 8.91M/8.91M [00:00<00:00, 64.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d pariza/bbc-news-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7c2263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "business = os.listdir(\"BBC News Summary/News Articles/business\")\n",
    "entertainment = os.listdir(\"BBC News Summary/News Articles/entertainment\")\n",
    "politices = os.listdir(\"BBC News Summary/News Articles/politics\")\n",
    "sports = os.listdir(\"BBC News Summary/News Articles/sport\")\n",
    "tech = os.listdir(\"BBC News Summary/News Articles/tech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c49ab318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['086.txt',\n",
       " '023.txt',\n",
       " '426.txt',\n",
       " '244.txt',\n",
       " '322.txt',\n",
       " '496.txt',\n",
       " '262.txt',\n",
       " '033.txt',\n",
       " '444.txt',\n",
       " '174.txt',\n",
       " '187.txt',\n",
       " '485.txt',\n",
       " '117.txt',\n",
       " '127.txt',\n",
       " '433.txt',\n",
       " '329.txt',\n",
       " '400.txt',\n",
       " '360.txt',\n",
       " '363.txt',\n",
       " '102.txt',\n",
       " '450.txt',\n",
       " '284.txt',\n",
       " '067.txt',\n",
       " '328.txt',\n",
       " '235.txt',\n",
       " '077.txt',\n",
       " '301.txt',\n",
       " '046.txt',\n",
       " '225.txt',\n",
       " '013.txt',\n",
       " '396.txt',\n",
       " '176.txt',\n",
       " '465.txt',\n",
       " '034.txt',\n",
       " '182.txt',\n",
       " '429.txt',\n",
       " '130.txt',\n",
       " '412.txt',\n",
       " '103.txt',\n",
       " '157.txt',\n",
       " '237.txt',\n",
       " '374.txt',\n",
       " '019.txt',\n",
       " '313.txt',\n",
       " '296.txt',\n",
       " '014.txt',\n",
       " '292.txt',\n",
       " '218.txt',\n",
       " '287.txt',\n",
       " '333.txt',\n",
       " '416.txt',\n",
       " '016.txt',\n",
       " '089.txt',\n",
       " '227.txt',\n",
       " '242.txt',\n",
       " '338.txt',\n",
       " '508.txt',\n",
       " '417.txt',\n",
       " '501.txt',\n",
       " '368.txt',\n",
       " '171.txt',\n",
       " '053.txt',\n",
       " '140.txt',\n",
       " '041.txt',\n",
       " '121.txt',\n",
       " '061.txt',\n",
       " '009.txt',\n",
       " '149.txt',\n",
       " '208.txt',\n",
       " '337.txt',\n",
       " '004.txt',\n",
       " '175.txt',\n",
       " '107.txt',\n",
       " '007.txt',\n",
       " '276.txt',\n",
       " '385.txt',\n",
       " '181.txt',\n",
       " '489.txt',\n",
       " '001.txt',\n",
       " '431.txt',\n",
       " '377.txt',\n",
       " '492.txt',\n",
       " '388.txt',\n",
       " '050.txt',\n",
       " '391.txt',\n",
       " '205.txt',\n",
       " '259.txt',\n",
       " '091.txt',\n",
       " '479.txt',\n",
       " '326.txt',\n",
       " '500.txt',\n",
       " '115.txt',\n",
       " '463.txt',\n",
       " '075.txt',\n",
       " '308.txt',\n",
       " '310.txt',\n",
       " '232.txt',\n",
       " '018.txt',\n",
       " '082.txt',\n",
       " '267.txt',\n",
       " '336.txt',\n",
       " '189.txt',\n",
       " '172.txt',\n",
       " '250.txt',\n",
       " '481.txt',\n",
       " '042.txt',\n",
       " '192.txt',\n",
       " '277.txt',\n",
       " '099.txt',\n",
       " '238.txt',\n",
       " '090.txt',\n",
       " '047.txt',\n",
       " '226.txt',\n",
       " '198.txt',\n",
       " '394.txt',\n",
       " '190.txt',\n",
       " '323.txt',\n",
       " '382.txt',\n",
       " '306.txt',\n",
       " '414.txt',\n",
       " '087.txt',\n",
       " '260.txt',\n",
       " '209.txt',\n",
       " '110.txt',\n",
       " '320.txt',\n",
       " '224.txt',\n",
       " '229.txt',\n",
       " '101.txt',\n",
       " '032.txt',\n",
       " '331.txt',\n",
       " '079.txt',\n",
       " '273.txt',\n",
       " '012.txt',\n",
       " '151.txt',\n",
       " '372.txt',\n",
       " '008.txt',\n",
       " '239.txt',\n",
       " '334.txt',\n",
       " '487.txt',\n",
       " '139.txt',\n",
       " '240.txt',\n",
       " '215.txt',\n",
       " '141.txt',\n",
       " '304.txt',\n",
       " '271.txt',\n",
       " '443.txt',\n",
       " '221.txt',\n",
       " '436.txt',\n",
       " '491.txt',\n",
       " '474.txt',\n",
       " '216.txt',\n",
       " '243.txt',\n",
       " '252.txt',\n",
       " '164.txt',\n",
       " '291.txt',\n",
       " '026.txt',\n",
       " '078.txt',\n",
       " '212.txt',\n",
       " '161.txt',\n",
       " '483.txt',\n",
       " '236.txt',\n",
       " '031.txt',\n",
       " '080.txt',\n",
       " '325.txt',\n",
       " '043.txt',\n",
       " '315.txt',\n",
       " '345.txt',\n",
       " '160.txt',\n",
       " '128.txt',\n",
       " '343.txt',\n",
       " '059.txt',\n",
       " '269.txt',\n",
       " '359.txt',\n",
       " '432.txt',\n",
       " '072.txt',\n",
       " '183.txt',\n",
       " '335.txt',\n",
       " '214.txt',\n",
       " '302.txt',\n",
       " '193.txt',\n",
       " '295.txt',\n",
       " '084.txt',\n",
       " '285.txt',\n",
       " '427.txt',\n",
       " '017.txt',\n",
       " '159.txt',\n",
       " '257.txt',\n",
       " '268.txt',\n",
       " '185.txt',\n",
       " '493.txt',\n",
       " '245.txt',\n",
       " '357.txt',\n",
       " '307.txt',\n",
       " '063.txt',\n",
       " '298.txt',\n",
       " '081.txt',\n",
       " '453.txt',\n",
       " '152.txt',\n",
       " '482.txt',\n",
       " '040.txt',\n",
       " '278.txt',\n",
       " '367.txt',\n",
       " '133.txt',\n",
       " '066.txt',\n",
       " '100.txt',\n",
       " '167.txt',\n",
       " '010.txt',\n",
       " '231.txt',\n",
       " '425.txt',\n",
       " '202.txt',\n",
       " '379.txt',\n",
       " '303.txt',\n",
       " '058.txt',\n",
       " '038.txt',\n",
       " '219.txt',\n",
       " '170.txt',\n",
       " '283.txt',\n",
       " '473.txt',\n",
       " '305.txt',\n",
       " '165.txt',\n",
       " '203.txt',\n",
       " '386.txt',\n",
       " '437.txt',\n",
       " '119.txt',\n",
       " '274.txt',\n",
       " '228.txt',\n",
       " '506.txt',\n",
       " '105.txt',\n",
       " '162.txt',\n",
       " '387.txt',\n",
       " '319.txt',\n",
       " '344.txt',\n",
       " '029.txt',\n",
       " '083.txt',\n",
       " '403.txt',\n",
       " '480.txt',\n",
       " '478.txt',\n",
       " '411.txt',\n",
       " '497.txt',\n",
       " '136.txt',\n",
       " '327.txt',\n",
       " '025.txt',\n",
       " '399.txt',\n",
       " '401.txt',\n",
       " '498.txt',\n",
       " '430.txt',\n",
       " '138.txt',\n",
       " '355.txt',\n",
       " '256.txt',\n",
       " '163.txt',\n",
       " '389.txt',\n",
       " '094.txt',\n",
       " '442.txt',\n",
       " '044.txt',\n",
       " '204.txt',\n",
       " '434.txt',\n",
       " '371.txt',\n",
       " '144.txt',\n",
       " '146.txt',\n",
       " '365.txt',\n",
       " '404.txt',\n",
       " '093.txt',\n",
       " '438.txt',\n",
       " '197.txt',\n",
       " '282.txt',\n",
       " '511.txt',\n",
       " '423.txt',\n",
       " '006.txt',\n",
       " '150.txt',\n",
       " '309.txt',\n",
       " '248.txt',\n",
       " '122.txt',\n",
       " '459.txt',\n",
       " '314.txt',\n",
       " '196.txt',\n",
       " '097.txt',\n",
       " '348.txt',\n",
       " '504.txt',\n",
       " '410.txt',\n",
       " '415.txt',\n",
       " '247.txt',\n",
       " '249.txt',\n",
       " '030.txt',\n",
       " '495.txt',\n",
       " '486.txt',\n",
       " '134.txt',\n",
       " '397.txt',\n",
       " '258.txt',\n",
       " '280.txt',\n",
       " '290.txt',\n",
       " '484.txt',\n",
       " '261.txt',\n",
       " '353.txt',\n",
       " '279.txt',\n",
       " '318.txt',\n",
       " '440.txt',\n",
       " '021.txt',\n",
       " '510.txt',\n",
       " '286.txt',\n",
       " '332.txt',\n",
       " '264.txt',\n",
       " '132.txt',\n",
       " '297.txt',\n",
       " '027.txt',\n",
       " '074.txt',\n",
       " '422.txt',\n",
       " '454.txt',\n",
       " '123.txt',\n",
       " '154.txt',\n",
       " '393.txt',\n",
       " '312.txt',\n",
       " '088.txt',\n",
       " '375.txt',\n",
       " '002.txt',\n",
       " '241.txt',\n",
       " '116.txt',\n",
       " '471.txt',\n",
       " '407.txt',\n",
       " '466.txt',\n",
       " '494.txt',\n",
       " '206.txt',\n",
       " '246.txt',\n",
       " '370.txt',\n",
       " '037.txt',\n",
       " '381.txt',\n",
       " '071.txt',\n",
       " '293.txt',\n",
       " '015.txt',\n",
       " '502.txt',\n",
       " '114.txt',\n",
       " '445.txt',\n",
       " '022.txt',\n",
       " '405.txt',\n",
       " '052.txt',\n",
       " '179.txt',\n",
       " '142.txt',\n",
       " '265.txt',\n",
       " '351.txt',\n",
       " '435.txt',\n",
       " '234.txt',\n",
       " '340.txt',\n",
       " '503.txt',\n",
       " '036.txt',\n",
       " '509.txt',\n",
       " '383.txt',\n",
       " '266.txt',\n",
       " '051.txt',\n",
       " '085.txt',\n",
       " '156.txt',\n",
       " '272.txt',\n",
       " '413.txt',\n",
       " '321.txt',\n",
       " '104.txt',\n",
       " '347.txt',\n",
       " '499.txt',\n",
       " '064.txt',\n",
       " '475.txt',\n",
       " '173.txt',\n",
       " '263.txt',\n",
       " '124.txt',\n",
       " '457.txt',\n",
       " '210.txt',\n",
       " '147.txt',\n",
       " '011.txt',\n",
       " '065.txt',\n",
       " '222.txt',\n",
       " '364.txt',\n",
       " '455.txt',\n",
       " '458.txt',\n",
       " '311.txt',\n",
       " '339.txt',\n",
       " '378.txt',\n",
       " '195.txt',\n",
       " '356.txt',\n",
       " '369.txt',\n",
       " '460.txt',\n",
       " '288.txt',\n",
       " '270.txt',\n",
       " '428.txt',\n",
       " '251.txt',\n",
       " '054.txt',\n",
       " '073.txt',\n",
       " '109.txt',\n",
       " '125.txt',\n",
       " '469.txt',\n",
       " '062.txt',\n",
       " '366.txt',\n",
       " '039.txt',\n",
       " '376.txt',\n",
       " '439.txt',\n",
       " '076.txt',\n",
       " '145.txt',\n",
       " '358.txt',\n",
       " '191.txt',\n",
       " '095.txt',\n",
       " '178.txt',\n",
       " '421.txt',\n",
       " '361.txt',\n",
       " '447.txt',\n",
       " '168.txt',\n",
       " '113.txt',\n",
       " '186.txt',\n",
       " '120.txt',\n",
       " '255.txt',\n",
       " '281.txt',\n",
       " '166.txt',\n",
       " '048.txt',\n",
       " '446.txt',\n",
       " '408.txt',\n",
       " '024.txt',\n",
       " '317.txt',\n",
       " '137.txt',\n",
       " '199.txt',\n",
       " '424.txt',\n",
       " '112.txt',\n",
       " '106.txt',\n",
       " '060.txt',\n",
       " '096.txt',\n",
       " '230.txt',\n",
       " '201.txt',\n",
       " '020.txt',\n",
       " '069.txt',\n",
       " '316.txt',\n",
       " '390.txt',\n",
       " '398.txt',\n",
       " '092.txt',\n",
       " '005.txt',\n",
       " '468.txt',\n",
       " '045.txt',\n",
       " '294.txt',\n",
       " '350.txt',\n",
       " '456.txt',\n",
       " '180.txt',\n",
       " '477.txt',\n",
       " '406.txt',\n",
       " '373.txt',\n",
       " '490.txt',\n",
       " '467.txt',\n",
       " '462.txt',\n",
       " '220.txt',\n",
       " '452.txt',\n",
       " '111.txt',\n",
       " '392.txt',\n",
       " '155.txt',\n",
       " '135.txt',\n",
       " '488.txt',\n",
       " '003.txt',\n",
       " '402.txt',\n",
       " '352.txt',\n",
       " '476.txt',\n",
       " '049.txt',\n",
       " '342.txt',\n",
       " '098.txt',\n",
       " '409.txt',\n",
       " '505.txt',\n",
       " '194.txt',\n",
       " '253.txt',\n",
       " '118.txt',\n",
       " '448.txt',\n",
       " '233.txt',\n",
       " '108.txt',\n",
       " '470.txt',\n",
       " '126.txt',\n",
       " '153.txt',\n",
       " '035.txt',\n",
       " '068.txt',\n",
       " '299.txt',\n",
       " '380.txt',\n",
       " '289.txt',\n",
       " '057.txt',\n",
       " '420.txt',\n",
       " '070.txt',\n",
       " '211.txt',\n",
       " '461.txt',\n",
       " '158.txt',\n",
       " '346.txt',\n",
       " '056.txt',\n",
       " '472.txt',\n",
       " '213.txt',\n",
       " '330.txt',\n",
       " '131.txt',\n",
       " '200.txt',\n",
       " '441.txt',\n",
       " '169.txt',\n",
       " '188.txt',\n",
       " '507.txt',\n",
       " '300.txt',\n",
       " '028.txt',\n",
       " '207.txt',\n",
       " '449.txt',\n",
       " '362.txt',\n",
       " '464.txt',\n",
       " '419.txt',\n",
       " '324.txt',\n",
       " '275.txt',\n",
       " '184.txt',\n",
       " '254.txt',\n",
       " '384.txt',\n",
       " '129.txt',\n",
       " '148.txt',\n",
       " '418.txt',\n",
       " '143.txt',\n",
       " '395.txt',\n",
       " '354.txt',\n",
       " '349.txt',\n",
       " '223.txt',\n",
       " '217.txt',\n",
       " '451.txt',\n",
       " '055.txt',\n",
       " '177.txt',\n",
       " '341.txt']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39e8b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_idx = np.arange(len(business))\n",
    "np.random.shuffle(business_idx)\n",
    "business_idx = business_idx[:200]\n",
    "\n",
    "entertainment_idx = np.arange(len(entertainment))\n",
    "np.random.shuffle(entertainment_idx)\n",
    "entertainment_idx = entertainment_idx[:200]\n",
    "\n",
    "politices_idx = np.arange(len(politices))\n",
    "np.random.shuffle(politices_idx)\n",
    "politices_idx = politices_idx[:200]\n",
    "\n",
    "sports_idx = np.arange(len(sports))\n",
    "np.random.shuffle(sports_idx)\n",
    "sports_idx = sports_idx[:200]\n",
    "\n",
    "tech_idx = np.arange(len(tech))\n",
    "np.random.shuffle(tech_idx)\n",
    "tech_idx = tech_idx[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e8c40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(base_article_path, base_summary_path, files):\n",
    "  articles = []\n",
    "  summaries = []\n",
    "  for file in files:\n",
    "    with open(base_article_path+\"/\"+file, \"r\", encoding=\"unicode_escape\") as f:\n",
    "      articles.append(f.read())\n",
    "    with open(base_summary_path+\"/\"+file, \"r\", encoding=\"unicode_escape\") as f:\n",
    "      summaries.append(f.read())\n",
    "  \n",
    "  return articles, summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f794e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "# from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f354d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kmeans_summary:\n",
    "    def __init__(self, k, embeddings, w2v=True):\n",
    "        self.k = k\n",
    "        self.embeddings = embeddings\n",
    "        self.w2v = w2v\n",
    "        \n",
    "    def summarize(self, doc):\n",
    "        sentences = self.tokenize_sentences(doc)\n",
    "        self.sentence_embeddings = self.embed_sentences(sentences)\n",
    "        kmeans = KMeans(n_clusters=self.k, random_state=42).fit(self.sentence_embeddings)\n",
    "        self.centroids = kmeans.cluster_centers_\n",
    "        summary = []\n",
    "        already_used = set()\n",
    "        for centroid in self.centroids:\n",
    "            closest_sent_indices = np.argsort(np.linalg.norm(centroid - self.sentence_embeddings, axis=1))\n",
    "            for idx in closest_sent_indices:\n",
    "                if idx not in already_used:\n",
    "                    already_used.add(idx)\n",
    "                    summary.append(sentences[idx])\n",
    "                    break\n",
    "                    \n",
    "        return \" \".join(summary), kmeans.inertia_\n",
    "        \n",
    "    def tokenize_sentences(self, document):\n",
    "        sentences =[]        \n",
    "        sentences = sent_tokenize(document)    \n",
    "        for sentence in sentences:        \n",
    "            sentence.replace(\"[^a-zA-Z0-9]\",\" \")     \n",
    "        return sentences\n",
    "\n",
    "    def embed_sentences(self, sentences):\n",
    "        sentence_embeddings = []\n",
    "        if self.w2v:\n",
    "            # w2v\n",
    "            for sent in sentences:\n",
    "                sent = [w.lower() for w in sent.split()]\n",
    "                # construct bag-of-words representation of sentences\n",
    "                s_emb = np.zeros(300)\n",
    "                for i in range(len(sent)):\n",
    "                    try:\n",
    "                        s_emb += self.embeddings[sent[i].encode()]\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                sentence_embeddings.append(s_emb)\n",
    "        else:\n",
    "            # BERt\n",
    "            sentence_embeddings = self.embeddings.encode(sentences)\n",
    "        return np.array(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "906f2a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target embedding mean rouge-1 scores:  0.48446779433505155\n",
      "context embedding mean rouge-1 scores:  0.48507599694020426\n",
      "\n",
      "target embedding mean rouge-2 scores:  0.3623159665490476\n",
      "context embedding mean rouge-2 scores:  0.3626167926212006\n",
      "\n",
      "target embedding mean rouge-L scores:  0.4744745503125241\n",
      "context embedding mean rouge-L scores:  0.47567039079697754\n",
      "\n",
      "target embedding mean inertia:  1831.590204272774\n",
      "context embeddings mean inertia:  6635.402678283306\n"
     ]
    }
   ],
   "source": [
    "# business_files = [business[idx] for idx in business_idx]\n",
    "business_articles, business_summaries = get_articles(\"BBC News Summary/News Articles/business\", \"BBC News Summary/Summaries/business\", business)\n",
    "\n",
    "target_scores = {\"1\": [], \"2\": [], \"L\": [], \"inertia\": []}\n",
    "context_scores = {\"1\": [], \"2\": [], \"L\": [], \"inertia\": []}\n",
    "for article, highlight in zip(business_articles, business_summaries):\n",
    "    # target_summary = summarize(article, 5, w2v_similarity, stopwords, target_embeddings)\n",
    "    summarizer = kmeans_summary(3, target_embeddings, True)\n",
    "    target_summary, target_inertia = summarizer.summarize(article)\n",
    "    scores = rouge.get_scores(target_summary, highlight)[0]\n",
    "    target_scores[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    target_scores[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    target_scores[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    target_scores[\"inertia\"].append(target_inertia)\n",
    "    \n",
    "    # context_summary = summarize(article, 3, w2v_similarity, stopwords, context_embeddings)\n",
    "    summarizer = kmeans_summary(3, context_embeddings, True)\n",
    "    context_summary, context_inertia = summarizer.summarize(article)\n",
    "    scores = rouge.get_scores(context_summary, highlight)[0]\n",
    "    context_scores[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    context_scores[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    context_scores[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    context_scores[\"inertia\"].append(context_inertia)\n",
    "\n",
    "print(\"target embedding mean rouge-1 scores: \", np.mean(target_scores[\"1\"]))\n",
    "print(\"context embedding mean rouge-1 scores: \", np.mean(context_scores[\"1\"]))\n",
    "print()\n",
    "print(\"target embedding mean rouge-2 scores: \", np.mean(target_scores[\"2\"]))\n",
    "print(\"context embedding mean rouge-2 scores: \", np.mean(context_scores[\"2\"]))\n",
    "print()\n",
    "print(\"target embedding mean rouge-L scores: \", np.mean(target_scores[\"L\"]))\n",
    "print(\"context embedding mean rouge-L scores: \", np.mean(context_scores[\"L\"]))\n",
    "print()\n",
    "print(\"target embedding mean inertia: \", np.mean(target_scores[\"inertia\"]))\n",
    "print(\"context embeddings mean inertia: \", np.mean(context_scores[\"inertia\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fe53fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target embedding mean rouge-1 scores:  0.4649592838917797\n",
      "context embedding mean rouge-1 scores:  0.4600814217452546\n",
      "\n",
      "target embedding mean rouge-2 scores:  0.3836113515824953\n",
      "context embedding mean rouge-2 scores:  0.3755093359485161\n",
      "\n",
      "target embedding mean rouge-L scores:  0.4649592838917797\n",
      "context embedding mean rouge-L scores:  0.4600814217452546\n",
      "\n",
      "target embedding mean inertia:  1972.1541542179739\n",
      "context embeddings mean inertia:  7539.831847117401\n"
     ]
    }
   ],
   "source": [
    "entertainment_articles, entertainment_summaries = get_articles(\"BBC News Summary/News Articles/entertainment\", \"BBC News Summary/Summaries/entertainment\", entertainment)\n",
    "\n",
    "target_scores = {\"1\": [], \"2\": [], \"L\": [], \"inertia\": []}\n",
    "context_scores = {\"1\": [], \"2\": [], \"L\": [], \"inertia\": []}\n",
    "for article, highlight in zip(entertainment_articles, entertainment_articles):\n",
    "    # target_summary = summarize(article, 5, w2v_similarity, stopwords, target_embeddings)\n",
    "    summarizer = kmeans_summary(3, target_embeddings, True)\n",
    "    target_summary, target_inertia = summarizer.summarize(article)\n",
    "    scores = rouge.get_scores(target_summary, highlight)[0]\n",
    "    target_scores[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    target_scores[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    target_scores[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    target_scores[\"inertia\"].append(target_inertia)\n",
    "    \n",
    "    # context_summary = summarize(article, 3, w2v_similarity, stopwords, context_embeddings)\n",
    "    summarizer = kmeans_summary(3, context_embeddings, True)\n",
    "    context_summary, context_inertia = summarizer.summarize(article)\n",
    "    scores = rouge.get_scores(context_summary, highlight)[0]\n",
    "    context_scores[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    context_scores[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    context_scores[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    context_scores[\"inertia\"].append(context_inertia)\n",
    "\n",
    "print(\"target embedding mean rouge-1 scores: \", np.mean(target_scores[\"1\"]))\n",
    "print(\"context embedding mean rouge-1 scores: \", np.mean(context_scores[\"1\"]))\n",
    "print()\n",
    "print(\"target embedding mean rouge-2 scores: \", np.mean(target_scores[\"2\"]))\n",
    "print(\"context embedding mean rouge-2 scores: \", np.mean(context_scores[\"2\"]))\n",
    "print()\n",
    "print(\"target embedding mean rouge-L scores: \", np.mean(target_scores[\"L\"]))\n",
    "print(\"context embedding mean rouge-L scores: \", np.mean(context_scores[\"L\"]))\n",
    "print()\n",
    "print(\"target embedding mean inertia: \", np.mean(target_scores[\"inertia\"]))\n",
    "print(\"context embeddings mean inertia: \", np.mean(context_scores[\"inertia\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c52a841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target embedding mean rouge-1 scores:  0.43845072520420403\n",
      "context embedding mean rouge-1 scores:  0.43987424727665364\n",
      "\n",
      "target embedding mean rouge-2 scores:  0.31221194124999674\n",
      "context embedding mean rouge-2 scores:  0.31332468549459197\n",
      "\n",
      "target embedding mean rouge-L scores:  0.4259304006729022\n",
      "context embedding mean rouge-L scores:  0.42856199010863577\n",
      "\n",
      "target embedding mean inertia:  2949.7810391929734\n",
      "context embeddings mean inertia:  10967.350713339454\n"
     ]
    }
   ],
   "source": [
    "politics_articles, politics_summaries = get_articles(\"BBC News Summary/News Articles/politics\", \"BBC News Summary/Summaries/politics\", politices)\n",
    "\n",
    "target_scores = {\"1\": [], \"2\": [], \"L\": [], \"inertia\": []}\n",
    "context_scores = {\"1\": [], \"2\": [], \"L\": [], \"inertia\": []}\n",
    "for article, highlight in zip(politics_articles, politics_summaries):\n",
    "    # target_summary = summarize(article, 5, w2v_similarity, stopwords, target_embeddings)\n",
    "    summarizer = kmeans_summary(3, target_embeddings, True)\n",
    "    target_summary, target_inertia = summarizer.summarize(article)\n",
    "    scores = rouge.get_scores(target_summary, highlight)[0]\n",
    "    target_scores[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    target_scores[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    target_scores[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    target_scores[\"inertia\"].append(target_inertia)\n",
    "    \n",
    "    # context_summary = summarize(article, 3, w2v_similarity, stopwords, context_embeddings)\n",
    "    summarizer = kmeans_summary(3, context_embeddings, True)\n",
    "    context_summary, context_inertia = summarizer.summarize(article)\n",
    "    scores = rouge.get_scores(context_summary, highlight)[0]\n",
    "    context_scores[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    context_scores[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    context_scores[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    context_scores[\"inertia\"].append(context_inertia)\n",
    "\n",
    "print(\"target embedding mean rouge-1 scores: \", np.mean(target_scores[\"1\"]))\n",
    "print(\"context embedding mean rouge-1 scores: \", np.mean(context_scores[\"1\"]))\n",
    "print()\n",
    "print(\"target embedding mean rouge-2 scores: \", np.mean(target_scores[\"2\"]))\n",
    "print(\"context embedding mean rouge-2 scores: \", np.mean(context_scores[\"2\"]))\n",
    "print()\n",
    "print(\"target embedding mean rouge-L scores: \", np.mean(target_scores[\"L\"]))\n",
    "print(\"context embedding mean rouge-L scores: \", np.mean(context_scores[\"L\"]))\n",
    "print()\n",
    "print(\"target embedding mean inertia: \", np.mean(target_scores[\"inertia\"]))\n",
    "print(\"context embeddings mean inertia: \", np.mean(context_scores[\"inertia\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e11611f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target embedding mean rouge-1 scores:  0.45478531306667214\n",
      "context embedding mean rouge-1 scores:  0.454773778864706\n",
      "\n",
      "target embedding mean rouge-2 scores:  0.3696538696931351\n",
      "context embedding mean rouge-2 scores:  0.3670951366986988\n",
      "\n",
      "target embedding mean rouge-L scores:  0.45478531306667214\n",
      "context embedding mean rouge-L scores:  0.454773778864706\n",
      "\n",
      "target embedding mean inertia:  1928.953702188919\n",
      "context embeddings mean inertia:  7698.8427032012505\n"
     ]
    }
   ],
   "source": [
    "sport_articles, sport_summaries = get_articles(\"BBC News Summary/News Articles/sport\", \"BBC News Summary/Summaries/sport\", sports)\n",
    "\n",
    "target_scores = {\"1\": [], \"2\": [], \"L\": [], \"inertia\": []}\n",
    "context_scores = {\"1\": [], \"2\": [], \"L\": [], \"inertia\": []}\n",
    "for article, highlight in zip(sport_articles, sport_articles):\n",
    "    # target_summary = summarize(article, 5, w2v_similarity, stopwords, target_embeddings)\n",
    "    summarizer = kmeans_summary(3, target_embeddings, True)\n",
    "    target_summary, target_inertia = summarizer.summarize(article)\n",
    "    scores = rouge.get_scores(target_summary, highlight)[0]\n",
    "    target_scores[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    target_scores[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    target_scores[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    target_scores[\"inertia\"].append(target_inertia)\n",
    "    \n",
    "    # context_summary = summarize(article, 3, w2v_similarity, stopwords, context_embeddings)\n",
    "    summarizer = kmeans_summary(3, context_embeddings, True)\n",
    "    context_summary, context_inertia = summarizer.summarize(article)\n",
    "    scores = rouge.get_scores(context_summary, highlight)[0]\n",
    "    context_scores[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    context_scores[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    context_scores[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    context_scores[\"inertia\"].append(context_inertia)\n",
    "\n",
    "print(\"target embedding mean rouge-1 scores: \", np.mean(target_scores[\"1\"]))\n",
    "print(\"context embedding mean rouge-1 scores: \", np.mean(context_scores[\"1\"]))\n",
    "print()\n",
    "print(\"target embedding mean rouge-2 scores: \", np.mean(target_scores[\"2\"]))\n",
    "print(\"context embedding mean rouge-2 scores: \", np.mean(context_scores[\"2\"]))\n",
    "print()\n",
    "print(\"target embedding mean rouge-L scores: \", np.mean(target_scores[\"L\"]))\n",
    "print(\"context embedding mean rouge-L scores: \", np.mean(context_scores[\"L\"]))\n",
    "print()\n",
    "print(\"target embedding mean inertia: \", np.mean(target_scores[\"inertia\"]))\n",
    "print(\"context embeddings mean inertia: \", np.mean(context_scores[\"inertia\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2dfa9d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target embedding mean rouge-1 scores:  0.40735642936401506\n",
      "context embedding mean rouge-1 scores:  0.3965494286804119\n",
      "\n",
      "target embedding mean rouge-2 scores:  0.2708035441151582\n",
      "context embedding mean rouge-2 scores:  0.25992063789610753\n",
      "\n",
      "target embedding mean rouge-L scores:  0.39508979569909175\n",
      "context embedding mean rouge-L scores:  0.384862509307733\n",
      "\n",
      "target embedding mean inertia:  3133.4573033567003\n",
      "context embeddings mean inertia:  11204.29195798604\n"
     ]
    }
   ],
   "source": [
    "tech_articles, tech_summaries = get_articles(\"BBC News Summary/News Articles/tech\", \"BBC News Summary/Summaries/tech\", tech)\n",
    "\n",
    "target_scores = {\"1\": [], \"2\": [], \"L\": [], \"inertia\": []}\n",
    "context_scores = {\"1\": [], \"2\": [], \"L\": [], \"inertia\": []}\n",
    "for article, highlight in zip(tech_articles, tech_summaries):\n",
    "    # target_summary = summarize(article, 5, w2v_similarity, stopwords, target_embeddings)\n",
    "    summarizer = kmeans_summary(3, target_embeddings, True)\n",
    "    target_summary, target_inertia = summarizer.summarize(article)\n",
    "    scores = rouge.get_scores(target_summary, highlight)[0]\n",
    "    target_scores[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    target_scores[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    target_scores[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    target_scores[\"inertia\"].append(target_inertia)\n",
    "    \n",
    "    # context_summary = summarize(article, 3, w2v_similarity, stopwords, context_embeddings)\n",
    "    summarizer = kmeans_summary(3, context_embeddings, True)\n",
    "    context_summary, context_inertia = summarizer.summarize(article)\n",
    "    scores = rouge.get_scores(context_summary, highlight)[0]\n",
    "    context_scores[\"1\"].append(scores[\"rouge-1\"][\"f\"])\n",
    "    context_scores[\"2\"].append(scores[\"rouge-2\"][\"f\"])\n",
    "    context_scores[\"L\"].append(scores[\"rouge-l\"][\"f\"])\n",
    "    context_scores[\"inertia\"].append(context_inertia)\n",
    "\n",
    "print(\"target embedding mean rouge-1 scores: \", np.mean(target_scores[\"1\"]))\n",
    "print(\"context embedding mean rouge-1 scores: \", np.mean(context_scores[\"1\"]))\n",
    "print()\n",
    "print(\"target embedding mean rouge-2 scores: \", np.mean(target_scores[\"2\"]))\n",
    "print(\"context embedding mean rouge-2 scores: \", np.mean(context_scores[\"2\"]))\n",
    "print()\n",
    "print(\"target embedding mean rouge-L scores: \", np.mean(target_scores[\"L\"]))\n",
    "print(\"context embedding mean rouge-L scores: \", np.mean(context_scores[\"L\"]))\n",
    "print()\n",
    "print(\"target embedding mean inertia: \", np.mean(target_scores[\"inertia\"]))\n",
    "print(\"context embeddings mean inertia: \", np.mean(context_scores[\"inertia\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a4a80d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.1155955279127903, pvalue=0.26493029697549714)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "ttest_ind(target_scores[\"1\"], context_scores[\"1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03fa175",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "690e015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcdc46cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_norms = []\n",
    "context_norms = []\n",
    "for word in target_embeddings.keys():\n",
    "    target_norms.append(np.linalg.norm(target_embeddings[word], ord=2))\n",
    "    context_norms.append(np.linalg.norm(context_embeddings[word], ord=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc5e42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_norms.sort()\n",
    "context_norms.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6029e5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.655810223338891"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_norms = target_norms[:-1]\n",
    "context_norms = context_norms[:-1]\n",
    "target_norms[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7f2f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 50, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3633d6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(target_norms, bins, alpha=0.5, label=\"target\")\n",
    "plt.hist(context_norms, bins, alpha=0.5, label=\"context\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(\"norms_dist.png\",  dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d77e9d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_stopword_norms = []\n",
    "context_stop_word_norms = []\n",
    "for word in stop_words:\n",
    "    try:\n",
    "        target_stopword_norms.append(np.linalg.norm(target_embeddings[word.encode()], ord=2))\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        context_stop_word_norms.append(np.linalg.norm(context_embeddings[word.encode()], ord=2))\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5f242c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target stopword norms:  2.868715510650181\n",
      "Target average word norms:  1.8506821390406325\n",
      "Context stopword norms:  6.227275594849735\n",
      "Context average word norms:  17.743070366603913\n"
     ]
    }
   ],
   "source": [
    "print(\"Target stopword norms: \", np.mean(target_stopword_norms))\n",
    "print(\"Target average word norms: \", np.mean(target_norms))\n",
    "print(\"Context stopword norms: \", np.mean(context_stop_word_norms))\n",
    "print(\"Context average word norms: \", np.mean(context_norms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ee55ba",
   "metadata": {},
   "source": [
    "### U-MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cc930418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Jascon 4 had been 30m under water for three days and all 12 members of the crew were believed to have perished. Scroll down for videos . The two aircrafts were flying in formation and the skydivers had planned to jump in tandem.', 7706.523965428814)\n"
     ]
    }
   ],
   "source": [
    "article = test[\"article\"][test_indices[326]]\n",
    "highlights = test[\"highlights\"][test_indices[326]]\n",
    "summarizer = kmeans_summary(3, target_embeddings, True)\n",
    "print(summarizer.summarize(article))\n",
    "# print(highlights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3ed7b065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025974021015349236"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_scores[\"1\"][326]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a8258482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 300)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate([summarizer.sentence_embeddings, summarizer.centroids], axis=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5de87c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UMAP dimension reduction\n",
    "reducer = umap.UMAP(metric=\"euclidean\")\n",
    "embedding = reducer.fit_transform(X)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8fc95e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f8a46695b20>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(embedding[:47,0], embedding[:47,1])\n",
    "plt.scatter(embedding[47:,0], embedding[47:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6ffdd34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 300)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_context = np.zeros((100, 300))\n",
    "for i, key in enumerate(context_embeddings.keys()):\n",
    "    if len(context_embeddings[key]) == 2:\n",
    "        continue\n",
    "    X_context[i,:] = context_embeddings[key]\n",
    "    if i >= X_context.shape[0]-1:\n",
    "        break\n",
    "X_context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "08636067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 300)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_target = np.zeros((100, 300))\n",
    "for i, key in enumerate(target_embeddings.keys()):\n",
    "    if len(target_embeddings[key]) < 300:\n",
    "        continue\n",
    "    X_target[i,:] = target_embeddings[key]\n",
    "    if i >= X_target.shape[0]-1:\n",
    "        break\n",
    "X_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "535dee01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 300)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate([X_context, X_target], axis=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c7677bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UMAP dimension reduction\n",
    "reducer = umap.UMAP(metric=\"euclidean\")\n",
    "embedding = reducer.fit_transform(X)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "47b73abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(embedding[:100, 0], embedding[:100, 1], label=\"context\")\n",
    "plt.scatter(embedding[100:, 0], embedding[100:, 1], label=\"target\", alpha=0.5, s=1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d516a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
